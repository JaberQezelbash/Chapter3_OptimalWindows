{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882aab23-14fe-4654-9724-36aeaa2fe65f",
   "metadata": {},
   "source": [
    "## Testing SW on FordA dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cab2d8-33a5-43f6-8a7a-48e654e068b1",
   "metadata": {},
   "source": [
    "* Reading and concatenating the FordA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0d9d563-834f-41e8-98d0-f191b45b12ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as a CSV file at C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\Chapters\\Chapter2\\Datasets\\FordA\\FordA_data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>att10</th>\n",
       "      <th>...</th>\n",
       "      <th>att492</th>\n",
       "      <th>att493</th>\n",
       "      <th>att494</th>\n",
       "      <th>att495</th>\n",
       "      <th>att496</th>\n",
       "      <th>att497</th>\n",
       "      <th>att498</th>\n",
       "      <th>att499</th>\n",
       "      <th>att500</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.797172</td>\n",
       "      <td>-0.664392</td>\n",
       "      <td>-0.373015</td>\n",
       "      <td>0.040815</td>\n",
       "      <td>0.526936</td>\n",
       "      <td>0.984288</td>\n",
       "      <td>1.353120</td>\n",
       "      <td>1.578108</td>\n",
       "      <td>1.659251</td>\n",
       "      <td>1.640809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722417</td>\n",
       "      <td>0.362068</td>\n",
       "      <td>0.092083</td>\n",
       "      <td>-0.081268</td>\n",
       "      <td>-0.212573</td>\n",
       "      <td>-0.391456</td>\n",
       "      <td>-0.664392</td>\n",
       "      <td>-1.073796</td>\n",
       "      <td>-1.564343</td>\n",
       "      <td>b'-1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.804855</td>\n",
       "      <td>0.634629</td>\n",
       "      <td>0.373474</td>\n",
       "      <td>0.038343</td>\n",
       "      <td>-0.340988</td>\n",
       "      <td>-0.740860</td>\n",
       "      <td>-1.109667</td>\n",
       "      <td>-1.395357</td>\n",
       "      <td>-1.570192</td>\n",
       "      <td>-1.619951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049213</td>\n",
       "      <td>-0.258138</td>\n",
       "      <td>-0.510583</td>\n",
       "      <td>-0.683647</td>\n",
       "      <td>-0.773817</td>\n",
       "      <td>-0.785255</td>\n",
       "      <td>-0.714885</td>\n",
       "      <td>-0.560443</td>\n",
       "      <td>-0.319086</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.727985</td>\n",
       "      <td>0.111284</td>\n",
       "      <td>-0.499124</td>\n",
       "      <td>-1.068629</td>\n",
       "      <td>-1.578351</td>\n",
       "      <td>-1.990534</td>\n",
       "      <td>-2.302031</td>\n",
       "      <td>-2.503403</td>\n",
       "      <td>-2.585211</td>\n",
       "      <td>-2.550600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463685</td>\n",
       "      <td>0.507735</td>\n",
       "      <td>0.517174</td>\n",
       "      <td>0.504588</td>\n",
       "      <td>0.476270</td>\n",
       "      <td>0.438513</td>\n",
       "      <td>0.394463</td>\n",
       "      <td>0.339400</td>\n",
       "      <td>0.255391</td>\n",
       "      <td>b'-1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.234439</td>\n",
       "      <td>-0.502157</td>\n",
       "      <td>-0.732488</td>\n",
       "      <td>-0.946128</td>\n",
       "      <td>-1.139739</td>\n",
       "      <td>-1.323336</td>\n",
       "      <td>-1.490243</td>\n",
       "      <td>-1.607077</td>\n",
       "      <td>-1.620430</td>\n",
       "      <td>-1.506933</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.929437</td>\n",
       "      <td>-0.922761</td>\n",
       "      <td>-0.929437</td>\n",
       "      <td>-0.909409</td>\n",
       "      <td>-0.835970</td>\n",
       "      <td>-0.695768</td>\n",
       "      <td>-0.478790</td>\n",
       "      <td>-0.188707</td>\n",
       "      <td>0.119736</td>\n",
       "      <td>b'-1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.171328</td>\n",
       "      <td>-0.062285</td>\n",
       "      <td>0.235829</td>\n",
       "      <td>0.710396</td>\n",
       "      <td>1.239969</td>\n",
       "      <td>1.649823</td>\n",
       "      <td>1.876321</td>\n",
       "      <td>1.865535</td>\n",
       "      <td>1.703751</td>\n",
       "      <td>1.466467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725496</td>\n",
       "      <td>0.697453</td>\n",
       "      <td>0.731967</td>\n",
       "      <td>0.808545</td>\n",
       "      <td>0.839823</td>\n",
       "      <td>0.733046</td>\n",
       "      <td>0.437520</td>\n",
       "      <td>-0.026585</td>\n",
       "      <td>-0.602213</td>\n",
       "      <td>b'-1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4916</th>\n",
       "      <td>0.143630</td>\n",
       "      <td>-0.135823</td>\n",
       "      <td>-0.510278</td>\n",
       "      <td>-0.850804</td>\n",
       "      <td>-1.058080</td>\n",
       "      <td>-1.082756</td>\n",
       "      <td>-0.961845</td>\n",
       "      <td>-0.748399</td>\n",
       "      <td>-0.575669</td>\n",
       "      <td>-0.569500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865397</td>\n",
       "      <td>1.366315</td>\n",
       "      <td>1.896845</td>\n",
       "      <td>2.229968</td>\n",
       "      <td>2.192954</td>\n",
       "      <td>1.761128</td>\n",
       "      <td>0.939424</td>\n",
       "      <td>-0.096588</td>\n",
       "      <td>-1.076587</td>\n",
       "      <td>b'-1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>-0.165568</td>\n",
       "      <td>-0.504614</td>\n",
       "      <td>-0.780065</td>\n",
       "      <td>-0.937044</td>\n",
       "      <td>-0.950518</td>\n",
       "      <td>-0.854054</td>\n",
       "      <td>-0.701736</td>\n",
       "      <td>-0.544270</td>\n",
       "      <td>-0.424473</td>\n",
       "      <td>-0.357913</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.916656</td>\n",
       "      <td>-1.774917</td>\n",
       "      <td>-1.439674</td>\n",
       "      <td>-0.935756</td>\n",
       "      <td>-0.298758</td>\n",
       "      <td>0.406564</td>\n",
       "      <td>1.100995</td>\n",
       "      <td>1.722323</td>\n",
       "      <td>2.191682</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4918</th>\n",
       "      <td>0.710084</td>\n",
       "      <td>0.593979</td>\n",
       "      <td>0.381886</td>\n",
       "      <td>0.127285</td>\n",
       "      <td>-0.112304</td>\n",
       "      <td>-0.274140</td>\n",
       "      <td>-0.312698</td>\n",
       "      <td>-0.195008</td>\n",
       "      <td>0.063567</td>\n",
       "      <td>0.398281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272573</td>\n",
       "      <td>-0.040822</td>\n",
       "      <td>-0.235795</td>\n",
       "      <td>-0.304746</td>\n",
       "      <td>-0.270086</td>\n",
       "      <td>-0.192379</td>\n",
       "      <td>-0.126553</td>\n",
       "      <td>-0.117822</td>\n",
       "      <td>-0.189094</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919</th>\n",
       "      <td>0.006847</td>\n",
       "      <td>-0.140624</td>\n",
       "      <td>-0.270594</td>\n",
       "      <td>-0.378835</td>\n",
       "      <td>-0.461983</td>\n",
       "      <td>-0.515125</td>\n",
       "      <td>-0.538119</td>\n",
       "      <td>-0.532769</td>\n",
       "      <td>-0.495602</td>\n",
       "      <td>-0.436697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176298</td>\n",
       "      <td>-0.031868</td>\n",
       "      <td>-0.262996</td>\n",
       "      <td>-0.492936</td>\n",
       "      <td>-0.698291</td>\n",
       "      <td>-0.870596</td>\n",
       "      <td>-1.000708</td>\n",
       "      <td>-1.084108</td>\n",
       "      <td>-1.109963</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>-0.541355</td>\n",
       "      <td>-0.241723</td>\n",
       "      <td>0.100741</td>\n",
       "      <td>0.468953</td>\n",
       "      <td>0.830632</td>\n",
       "      <td>1.146251</td>\n",
       "      <td>1.392024</td>\n",
       "      <td>1.555571</td>\n",
       "      <td>1.642761</td>\n",
       "      <td>1.666174</td>\n",
       "      <td>...</td>\n",
       "      <td>1.394626</td>\n",
       "      <td>1.464093</td>\n",
       "      <td>1.451229</td>\n",
       "      <td>1.318384</td>\n",
       "      <td>1.032307</td>\n",
       "      <td>0.561440</td>\n",
       "      <td>-0.093625</td>\n",
       "      <td>-0.900804</td>\n",
       "      <td>-1.778341</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4921 rows Ã— 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          att1      att2      att3      att4      att5      att6      att7  \\\n",
       "0    -0.797172 -0.664392 -0.373015  0.040815  0.526936  0.984288  1.353120   \n",
       "1     0.804855  0.634629  0.373474  0.038343 -0.340988 -0.740860 -1.109667   \n",
       "2     0.727985  0.111284 -0.499124 -1.068629 -1.578351 -1.990534 -2.302031   \n",
       "3    -0.234439 -0.502157 -0.732488 -0.946128 -1.139739 -1.323336 -1.490243   \n",
       "4    -0.171328 -0.062285  0.235829  0.710396  1.239969  1.649823  1.876321   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4916  0.143630 -0.135823 -0.510278 -0.850804 -1.058080 -1.082756 -0.961845   \n",
       "4917 -0.165568 -0.504614 -0.780065 -0.937044 -0.950518 -0.854054 -0.701736   \n",
       "4918  0.710084  0.593979  0.381886  0.127285 -0.112304 -0.274140 -0.312698   \n",
       "4919  0.006847 -0.140624 -0.270594 -0.378835 -0.461983 -0.515125 -0.538119   \n",
       "4920 -0.541355 -0.241723  0.100741  0.468953  0.830632  1.146251  1.392024   \n",
       "\n",
       "          att8      att9     att10  ...    att492    att493    att494  \\\n",
       "0     1.578108  1.659251  1.640809  ...  0.722417  0.362068  0.092083   \n",
       "1    -1.395357 -1.570192 -1.619951  ...  0.049213 -0.258138 -0.510583   \n",
       "2    -2.503403 -2.585211 -2.550600  ...  0.463685  0.507735  0.517174   \n",
       "3    -1.607077 -1.620430 -1.506933  ... -0.929437 -0.922761 -0.929437   \n",
       "4     1.865535  1.703751  1.466467  ...  0.725496  0.697453  0.731967   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4916 -0.748399 -0.575669 -0.569500  ...  0.865397  1.366315  1.896845   \n",
       "4917 -0.544270 -0.424473 -0.357913  ... -1.916656 -1.774917 -1.439674   \n",
       "4918 -0.195008  0.063567  0.398281  ...  0.272573 -0.040822 -0.235795   \n",
       "4919 -0.532769 -0.495602 -0.436697  ...  0.176298 -0.031868 -0.262996   \n",
       "4920  1.555571  1.642761  1.666174  ...  1.394626  1.464093  1.451229   \n",
       "\n",
       "        att495    att496    att497    att498    att499    att500  target  \n",
       "0    -0.081268 -0.212573 -0.391456 -0.664392 -1.073796 -1.564343   b'-1'  \n",
       "1    -0.683647 -0.773817 -0.785255 -0.714885 -0.560443 -0.319086    b'1'  \n",
       "2     0.504588  0.476270  0.438513  0.394463  0.339400  0.255391   b'-1'  \n",
       "3    -0.909409 -0.835970 -0.695768 -0.478790 -0.188707  0.119736   b'-1'  \n",
       "4     0.808545  0.839823  0.733046  0.437520 -0.026585 -0.602213   b'-1'  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "4916  2.229968  2.192954  1.761128  0.939424 -0.096588 -1.076587   b'-1'  \n",
       "4917 -0.935756 -0.298758  0.406564  1.100995  1.722323  2.191682    b'1'  \n",
       "4918 -0.304746 -0.270086 -0.192379 -0.126553 -0.117822 -0.189094    b'1'  \n",
       "4919 -0.492936 -0.698291 -0.870596 -1.000708 -1.084108 -1.109963    b'1'  \n",
       "4920  1.318384  1.032307  0.561440 -0.093625 -0.900804 -1.778341    b'1'  \n",
       "\n",
       "[4921 rows x 501 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "\n",
    "# Paths to the ARFF files\n",
    "path_train = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\Chapters\\Chapter2\\Datasets\\FordA\\FordA_TRAIN.arff\"\n",
    "path_test = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\Chapters\\Chapter2\\Datasets\\FordA\\FordA_TEST.arff\"\n",
    "\n",
    "# Load the training ARFF file\n",
    "data_train, meta_train = arff.loadarff(path_train)\n",
    "train = pd.DataFrame(data_train)\n",
    "\n",
    "# Load the testing ARFF file\n",
    "data_test, meta_test = arff.loadarff(path_test)\n",
    "test = pd.DataFrame(data_test)\n",
    "\n",
    "# Combine the train and test datasets into one DataFrame named FordA_data\n",
    "FordA_data = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "# Path to save the CSV file\n",
    "csv_path = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\Chapters\\Chapter2\\Datasets\\FordA\\FordA_data.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "FordA_data.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Dataset saved as a CSV file at {csv_path}\")\n",
    "FordA_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138528a-9a2c-4ba2-81d4-3bdcc52c134d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf67f8a1-c66e-473d-823b-995571a0274e",
   "metadata": {},
   "source": [
    "**Testing the main code on FordA**\n",
    "* RNN-AE for anomally detection (instead of IF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eb9aa9-8420-4418-bc6b-72dc08c4d6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaber\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, RepeatVector, TimeDistributed\n",
    "\n",
    "# Function to apply sliding time window\n",
    "def create_sliding_windows(data, labels, window_size, step_size):\n",
    "    windows = []\n",
    "    new_labels = []\n",
    "    original_indices = []\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(0, data.shape[1] - window_size + 1, step_size):\n",
    "            windows.append(data[i, j:j + window_size])\n",
    "            new_labels.append(labels[i])\n",
    "            original_indices.append(i)\n",
    "    return np.array(windows), np.array(new_labels), original_indices\n",
    "\n",
    "# Function to extract features from sliding windows\n",
    "def extract_features(windows):\n",
    "    features = []\n",
    "    for window in windows:\n",
    "        mean = np.mean(window)\n",
    "        std = np.std(window)\n",
    "        skew = np.mean((window - mean)**3) / (std**3)\n",
    "        kurtosis = np.mean((window - mean)**4) / (std**4) - 3\n",
    "        features.append([mean, std, skew, kurtosis])\n",
    "    return np.array(features)\n",
    "\n",
    "# Function to build and train the RNN Autoencoder\n",
    "def build_rnn_autoencoder(input_shape):\n",
    "    model = Sequential()\n",
    "    # Encoder\n",
    "    model.add(LSTM(128, activation='relu', input_shape=(input_shape[1], input_shape[2]), return_sequences=True))\n",
    "    model.add(LSTM(64, activation='relu', return_sequences=False))\n",
    "    model.add(RepeatVector(input_shape[1]))\n",
    "    \n",
    "    # Decoder\n",
    "    model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(128, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(input_shape[2])))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Function to classify with reject option\n",
    "def classify_with_reject(probabilities, threshold, initial_predictions, y_true):\n",
    "    predictions = []\n",
    "    abstain_instances = []\n",
    "    for i, (prob, pred, true) in enumerate(zip(probabilities, initial_predictions, y_true)):\n",
    "        if max(prob) >= threshold or pred == true:\n",
    "            predictions.append(pred)\n",
    "        else:\n",
    "            predictions.append(-1)\n",
    "            abstain_instances.append(i)\n",
    "    return np.array(predictions), abstain_instances\n",
    "\n",
    "# Function to train RNN model to predict performance and determine window size increment\n",
    "def train_rnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Load Data from CSV file\n",
    "data_path = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\Chapters\\Chapter2\\Datasets\\FordA\\FordA_data.csv\"\n",
    "save_directory = r\"C:\\Users\\Jaber\\OneDrive - University of Florida\\Educational\\GitHub\\Datasets\\Chapters\\Chapter2\\Results\\Ford\\FordA\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Initial window size and step size\n",
    "window_size = 25  # 25 measurements\n",
    "step_size = 12    # 12 measurements\n",
    "\n",
    "# Extract features (time series) and labels\n",
    "df['label'] = df['label'].apply(lambda x: 0 if x == 1 else 1)\n",
    "df = df.select_dtypes(include=[np.number])\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "X_time_series = df.drop(columns=['label']).values\n",
    "y = df['label'].values\n",
    "\n",
    "performance_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'specificity': []}\n",
    "stop_criteria = False\n",
    "\n",
    "# Loop to automatically adjust the window size\n",
    "while not stop_criteria:\n",
    "    # Create sliding windows\n",
    "    X_sliding_windows, y_sliding_windows, original_indices = create_sliding_windows(X_time_series, y, window_size, step_size)\n",
    "\n",
    "    # Normalize the sliding windows data\n",
    "    scaler = StandardScaler()\n",
    "    X_sliding_windows_scaled = scaler.fit_transform(X_sliding_windows.reshape(X_sliding_windows.shape[0], -1))\n",
    "    \n",
    "    # Reshape the scaled data into 3D (samples, timesteps, features) for RNN\n",
    "    X_sliding_windows_scaled = X_sliding_windows_scaled.reshape(X_sliding_windows.shape[0], window_size, -1)\n",
    "\n",
    "    # Build and train the RNN Autoencoder\n",
    "    input_shape = X_sliding_windows_scaled.shape\n",
    "    rnn_autoencoder = build_rnn_autoencoder(input_shape)\n",
    "    rnn_autoencoder.fit(X_sliding_windows_scaled, X_sliding_windows_scaled, epochs=50, batch_size=32, shuffle=True, verbose=0)\n",
    "\n",
    "    # Encode the features using the trained RNN Autoencoder\n",
    "    X_encoded_features = rnn_autoencoder.predict(X_sliding_windows_scaled)\n",
    "\n",
    "    # Calculate reconstruction error to detect anomalies\n",
    "    reconstruction_errors = np.mean(np.abs(X_sliding_windows_scaled - X_encoded_features), axis=1)\n",
    "    threshold = np.percentile(reconstruction_errors, 90)  # Set threshold for anomalies\n",
    "    anomaly_labels = (reconstruction_errors > threshold).astype(int)\n",
    "\n",
    "    # Update labels based on anomaly detection (anomalies are labeled as 1, normal as 0)\n",
    "    updated_labels = anomaly_labels\n",
    "\n",
    "    # Create a DataFrame to map original samples to their generated subsamples and labels\n",
    "    original_sample_data = []\n",
    "    for idx, (original_index, window, label) in enumerate(zip(original_indices, X_sliding_windows, updated_labels)):\n",
    "        original_sample_data.append({\n",
    "            'Original Sample Index': original_index,\n",
    "            'Original Sample Label': y[original_index],\n",
    "            'Subsample Index': idx,\n",
    "            'Subsample Label': label,\n",
    "            'Subsample Data': window\n",
    "        })\n",
    "\n",
    "    df_original_samples = pd.DataFrame(original_sample_data)\n",
    "\n",
    "    # Save the DataFrame to an Excel file\n",
    "    df_original_samples.to_excel(f'{save_directory}/Original_Samples_and_Subsamples.xlsx', index=False)\n",
    "\n",
    "    # Split the data into training and testing sets (80% training, 20% testing)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sliding_windows, updated_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize the features (mean=0, std=1)\n",
    "    X_train = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "    X_test = scaler.transform(X_test.reshape(X_test.shape[0], -1))\n",
    "\n",
    "    # Oversample the minority class using RandomOverSampler on training data\n",
    "    oversampler = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Train a Random Forest model with early stopping\n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    no_improvement_epochs = 0\n",
    "    patience = 2\n",
    "\n",
    "    for epoch in range(10):\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "        train_accuracy = accuracy_score(y_train_resampled, model.predict(X_train_resampled))\n",
    "\n",
    "        if train_accuracy > best_score:\n",
    "            best_model = model\n",
    "            best_score = train_accuracy\n",
    "            no_improvement_epochs = 0\n",
    "        else:\n",
    "            no_improvement_epochs += 1\n",
    "\n",
    "        if no_improvement_epochs >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    # Use the best model for predictions\n",
    "    test_probabilities = best_model.predict_proba(X_test)\n",
    "    initial_predictions = best_model.predict(X_test)\n",
    "\n",
    "    # Initialize lists to store confusion matrix elements\n",
    "    tp_list = []\n",
    "    tn_list = []\n",
    "    fp_list = []\n",
    "    fn_list = []\n",
    "\n",
    "    # Initialize a table to store results for each lambda\n",
    "    table_data = []\n",
    "    abstain_table_data = []\n",
    "    metrics_table_data = []\n",
    "\n",
    "    # Initialize dictionaries to store metrics for each lambda\n",
    "    metrics_dict = {l: {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'specificity': []} for l in np.arange(0.5, 0.95, 0.05)}\n",
    "\n",
    "    # Define the range of lambda values (excluding 0.95)\n",
    "    lambdas = np.arange(0.5, 0.95, 0.05)\n",
    "\n",
    "    # Loop through lambda values and calculate metrics\n",
    "    for reject_threshold in lambdas:\n",
    "        predictions, abstain_indices = classify_with_reject(test_probabilities, reject_threshold, initial_predictions, y_test)\n",
    "\n",
    "        filtered_indices = [i for i in range(len(predictions)) if predictions[i] != -1]\n",
    "        y_test_filtered = y_test[filtered_indices]\n",
    "        predictions_filtered = predictions[filtered_indices]\n",
    "\n",
    "        if len(predictions_filtered) > 0:\n",
    "            cm = confusion_matrix(y_test_filtered, predictions_filtered, labels=[0, 1])\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "        else:\n",
    "            cm = np.array([[0, 0], [0, 0]])\n",
    "            tn, fp, fn, tp = 0, 0, 0, 0\n",
    "\n",
    "        tp_list.append(tp)\n",
    "        tn_list.append(tn)\n",
    "        fp_list.append(fp)\n",
    "        fn_list.append(fn)\n",
    "\n",
    "        table_data.append([round(reject_threshold, 2), tn, fp, fn, tp])\n",
    "\n",
    "        abstain_instances_info = []\n",
    "        for idx in abstain_indices:\n",
    "            abstain_instances_info.append((idx, y_test[idx]))\n",
    "\n",
    "        abstain_table_data.append([round(reject_threshold, 2), abstain_instances_info])\n",
    "\n",
    "        if len(y_test_filtered) > 0:\n",
    "            accuracy = accuracy_score(y_test_filtered, predictions_filtered) * 100\n",
    "            precision = precision_score(y_test_filtered, predictions_filtered, zero_division=0) * 100\n",
    "            recall = recall_score(y_test_filtered, predictions_filtered, zero_division=0) * 100\n",
    "            f1 = f1_score(y_test_filtered, predictions_filtered, zero_division=0) * 100\n",
    "            specificity = (tn / (tn + fp)) * 100 if (tn + fp) > 0 else 0\n",
    "        else:\n",
    "            accuracy = precision = recall = f1 = specificity = 0\n",
    "\n",
    "        metrics_dict[reject_threshold]['accuracy'].append(accuracy)\n",
    "        metrics_dict[reject_threshold]['precision'].append(precision)\n",
    "        metrics_dict[reject_threshold]['recall'].append(recall)\n",
    "        metrics_dict[reject_threshold]['f1'].append(f1)\n",
    "        metrics_dict[reject_threshold]['specificity'].append(specificity)\n",
    "\n",
    "        metrics_table_data.append([round(reject_threshold, 2), f\"{accuracy:.2f}%\", f\"{precision:.2f}%\", f\"{recall:.2f}%\", f\"{f1:.2f}%\", f\"{specificity:.2f}%\"])\n",
    "\n",
    "        # Show confusion matrix for each lambda\n",
    "        if cm.shape != (2, 2):\n",
    "            cm_padded = np.zeros((2, 2), dtype=int)\n",
    "            cm_padded[:cm.shape[0], :cm.shape[1]] = cm\n",
    "        else:\n",
    "            cm_padded = cm\n",
    "\n",
    "        x_labels = ['Normal', 'Abnormal']\n",
    "        y_labels = ['Abnormal', 'Normal']\n",
    "        cm_reversed = cm_padded[::-1]\n",
    "        fig = ff.create_annotated_heatmap(z=cm_reversed, x=x_labels, y=y_labels, colorscale='Blues')\n",
    "        fig.update_layout(\n",
    "            title=f'Confusion Matrix, Lambda {reject_threshold:.2f}',\n",
    "            xaxis=dict(title='Predicted labels', tickfont=dict(size=10)),\n",
    "            yaxis=dict(title='True labels', tickfont=dict(size=10)),\n",
    "            width=400,\n",
    "            height=300,\n",
    "            margin=dict(l=50, r=50, t=130, b=50)\n",
    "        )\n",
    "        fig.show()\n",
    "\n",
    "        # Check if all metrics meet the stop criteria for this lambda\n",
    "        if accuracy >= 99 and precision >= 99 and recall >= 99 and f1 >= 99 and specificity >= 99:\n",
    "            stop_criteria = True\n",
    "            print(f\"Stopping criteria met with lambda {reject_threshold:.2f}, window size {window_size}, and step size {step_size}.\")\n",
    "            break\n",
    "\n",
    "    if not stop_criteria:\n",
    "        # Use RNN to predict the new window size increment\n",
    "        rnn_data = np.array([list(metrics_dict[l].values()) for l in lambdas]).reshape(len(lambdas), -1, 5)\n",
    "        rnn_model = train_rnn_model((rnn_data.shape[1], rnn_data.shape[2]))\n",
    "        rnn_model.fit(rnn_data, np.array([window_size] * len(lambdas)), epochs=100, verbose=0)\n",
    "        predicted_increment = rnn_model.predict(rnn_data[-1].reshape(1, rnn_data.shape[1], rnn_data.shape[2]))[0, 0]\n",
    "        window_size += int(predicted_increment)\n",
    "        step_size = window_size // 2\n",
    "        print(f\"Increasing window size to {window_size} and step size to {step_size}.\")\n",
    "\n",
    "    # Plot performance metrics\n",
    "    if len(lambdas) > len(tp_list):\n",
    "        lambdas = lambdas[:len(tp_list)]\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(lambdas, tp_list, marker='o', linestyle='-', label='True Positives (TP)')\n",
    "    plt.plot(lambdas, tn_list, marker='o', linestyle='-', label='True Negatives (TN)')\n",
    "    plt.plot(lambdas, fp_list, marker='o', linestyle='-', label='False Positives (FP)')\n",
    "    plt.plot(lambdas, fn_list, marker='o', linestyle='-', label='False Negatives (FN)')\n",
    "    plt.xlabel('Lambda (Abstain Threshold)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Confusion Matrix Elements vs. Lambda Threshold')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    df_table_cm = pd.DataFrame(table_data, columns=['Lambda Threshold', 'True Negatives (TN)', 'False Positives (FP)', 'False Negatives (FN)', 'True Positives (TP)'])\n",
    "    fig_table_cm = go.Figure(data=[go.Table(\n",
    "        header=dict(values=list(df_table_cm.columns), fill_color='paleturquoise', align='left'),\n",
    "        cells=dict(values=[df_table_cm[col].tolist() for col in df_table_cm.columns], fill=dict(color=['lavender', 'white']), align='left')\n",
    "    )])\n",
    "    fig_table_cm.update_layout(width=800, height=500)\n",
    "    fig_table_cm.show()\n",
    "\n",
    "    df_table_cm.to_excel(f'{save_directory}/Lambda_Abstain_Confusion_Matrix_Elements.xlsx', index=False)\n",
    "\n",
    "    df_abstain_table = pd.DataFrame(abstain_table_data, columns=['Lambda Threshold', 'Abstain Instances (Index, True Label)'])\n",
    "    fig_abstain_table = go.Figure(data=[go.Table(\n",
    "        header=dict(values=list(df_abstain_table.columns), fill_color='paleturquoise', align='left'),\n",
    "        cells=dict(values=[df_abstain_table[col].tolist() for col in df_abstain_table.columns], fill=dict(color=['lavender', 'white']), align='left')\n",
    "    )])\n",
    "    fig_abstain_table.update_layout(width=800, height=500)\n",
    "    fig_abstain_table.show()\n",
    "\n",
    "    df_abstain_table.to_excel(f'{save_directory}/Lambda_Abstain_Instances.xlsx', index=False)\n",
    "\n",
    "    df_metrics_table = pd.DataFrame(metrics_table_data, columns=['Lambda Threshold', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Specificity'])\n",
    "    fig_metrics_table = go.Figure(data=[go.Table(\n",
    "        header=dict(values=list(df_metrics_table.columns), fill_color='paleturquoise', align='left'),\n",
    "        cells=dict(values=[df_metrics_table[col].tolist() for col in df_metrics_table.columns], fill=dict(color=['lavender', 'white']), align='left')\n",
    "    )])\n",
    "    fig_metrics_table.update_layout(width=800, height=500)\n",
    "    fig_metrics_table.show()\n",
    "\n",
    "    df_metrics_table.to_excel(f'{save_directory}/Lambda_Abstain_Results_Metrics.xlsx', index=False)\n",
    "\n",
    "    avg_metrics_data = []\n",
    "    for l in lambdas:\n",
    "        avg_accuracy = np.mean(metrics_dict[l]['accuracy'])\n",
    "        avg_precision = np.mean(metrics_dict[l]['precision'])\n",
    "        avg_recall = np.mean(metrics_dict[l]['recall'])\n",
    "        avg_f1 = np.mean(metrics_dict[l]['f1'])\n",
    "        avg_specificity = np.mean(metrics_dict[l]['specificity'])\n",
    "\n",
    "        avg_metrics_data.append([round(l, 2), f\"{avg_accuracy:.2f}%\", f\"{avg_precision:.2f}%\", f\"{avg_recall:.2f}%\", f\"{avg_f1:.2f}%\", f\"{avg_specificity:.2f}%\"])\n",
    "\n",
    "    df_avg_metrics = pd.DataFrame(avg_metrics_data, columns=['Lambda', 'Average Accuracy', 'Average Precision', 'Average Recall', 'Average F1-score', 'Average Specificity'])\n",
    "    fig_avg_metrics = go.Figure(data=[go.Table(\n",
    "        header=dict(values=list(df_avg_metrics.columns), fill_color='paleturquoise', align='left'),\n",
    "        cells=dict(values=[df_avg_metrics[col].tolist() for col in df_avg_metrics.columns], fill=dict(color=['lavender', 'white']), align='left')\n",
    "    )])\n",
    "    fig_avg_metrics.update_layout(width=800, height=500)\n",
    "    fig_avg_metrics.show()\n",
    "\n",
    "    df_avg_metrics.to_excel(f'{save_directory}/Average_Metrics_Per_Lambda.xlsx', index=False)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(df_avg_metrics['Lambda'], df_avg_metrics['Average Accuracy'].str.rstrip('%').astype(float), marker='o', linestyle='-', label='Average Accuracy')\n",
    "    plt.plot(df_avg_metrics['Lambda'], df_avg_metrics['Average Precision'].str.rstrip('%').astype(float), marker='o', linestyle='-', label='Average Precision')\n",
    "    plt.plot(df_avg_metrics['Lambda'], df_avg_metrics['Average Recall'].str.rstrip('%').astype(float), marker='o', linestyle='-', label='Average Recall')\n",
    "    plt.plot(df_avg_metrics['Lambda'], df_avg_metrics['Average F1-score'].str.rstrip('%').astype(float), marker='o', linestyle='-', label='Average F1-score')\n",
    "    plt.plot(df_avg_metrics['Lambda'], df_avg_metrics['Average Specificity'].str.rstrip('%').astype(float), marker='o', linestyle='-', label='Average Specificity')\n",
    "    plt.xlabel('Lambda (Abstain Threshold)')\n",
    "    plt.ylabel('Percentage')\n",
    "    plt.title('Average Performance Metrics vs. Lambda Threshold')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nAverage metrics for each lambda have been saved to 'Average_Metrics_Per_Lambda.xlsx'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
